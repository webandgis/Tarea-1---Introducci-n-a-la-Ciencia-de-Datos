





from time import time
from pathlib import Path
from wordcloud import WordCloud
import matplotlib.pyplot as plt

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx

# Agregue aqui el resto de las librerias que necesite
from dash import Dash, dcc, html, Input, Output
from collections import Counter
import plotly.graph_objects as go
import plotly.express as px
import numpy as np
import re

import pandas as pd
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import nltk



#### Descargar wordcloud para generar gráfico de palabra más frecuente


get_ipython().getoutput("pip install wordcloud")





# DataFrame con todos los discursos:
df_speeches = pd.read_csv("../data/us_2020_election_speeches.csv")
df_speeches





df_speeches.describe()





df_speeches.isnull().sum()





lista_filas_faltantes=df_speeches[df_speeches.isnull().any(axis=1)].index.tolist()
print('Las filas con datos null son las siguientes:',lista_filas_faltantes)
print('El número total de filas con datos faltantes es de:',len(lista_filas_faltantes))





#Identificar los valores nulls por campo de cada fila

lista_campos_nulls=df_speeches[df_speeches.isnull().any(axis=1)]

for i,row in lista_campos_nulls.iterrows():
  columnas_nulls=row[row.isnull()].index.tolist()
  print(f"Fila {i}:{', '.join(columnas_nulls)}")





df_speeches['speaker'].unique()





df_speeches['date'].unique()





df_speeches['location'].unique()





df_speeches['type'].unique()





# Separar las fechas por dia, mes y año
df_speeches['date']=pd.to_datetime(df_speeches['date'])
df_speeches['year']=df_speeches['date'].dt.year
df_speeches['month']=df_speeches['date'].dt.month
df_speeches['day']=df_speeches['date'].dt.day
df_speeches['month_str']=df_speeches['date'].dt.month_name(locale='en_US.UTF-8')











df_speeches_top_5=df_speeches['speaker'].value_counts().head(5)
df_speeches_top_5





# Convertir primero todo el campo speaker en str
df_speeches['speaker'] = df_speeches['speaker'].astype(str)
#Identificar los que están separadps por , lo cual indica hau mas de un orador
df_multiple_speakers = df_speeches[df_speeches['speaker'].str.contains(',')]
#Mostrar el data frame
df_multiple_speakers





#Crear un for para recorrer los speakers que están en el top 5 y sumarle si están en la variable de multiples oradores

for speaker in df_speeches_top_5.index:
     # Contar cuántas veces aparece el orador en la variable con múltiples oradores
    count_multiple_speakers=df_multiple_speakers['speaker'].str.contains(speaker).sum()

    #Asegurarse de contarlo una sola vez
    count_one_speaker=df_speeches[df_speeches['speaker']==speaker].shape[0]

    #Contar los multiples y unicos speakers
    df_speeches_top_5[speaker]= count_one_speaker + count_multiple_speakers

print(df_speeches_top_5)





## Visualizaciones 1 - Visualización por mes total (Solo discursos individuales)

#Ordenar la lista con los meses
meses_ordenados=['January', 'February','March','April','May','June','July','August','September','October']

#Identificar el top 5 mandatarios con más discursos
top5_mandatarios=df_speeches['speaker'].value_counts().head(5).index.tolist()

#Filtrar del dataframe orifinal el top 5 de mandatarios
df_top5=df_speeches[df_speeches['speaker'].isin(top5_mandatarios)]

#Convertir el mes en una categoría del gráfico
df_top5.loc[:,'month_str']=pd.Categorical(df_top5['month_str'],categories=meses_ordenados)

#Agrupar los mantararios y el mes de sus discursos
discursos_por_mes=df_top5.groupby(['speaker','month_str']).size().reset_index(name='total_discursos')

#Crear gráfico

fig_bar_total_mes=go.Figure()

for speaker in top5_mandatarios:
    df_speaker=discursos_por_mes[discursos_por_mes['speaker']==speaker]
    fig_bar_total_mes.add_trace(go.Bar(x=df_speaker['month_str'],
                                      y=df_speaker['total_discursos'],name=speaker))
#Configurar el layout del gráfico
fig_bar_total_mes.update_layout(
    title='Total discursos por mes del Top 5 mandatarios con mayor cantidad de discursos (Campaña presidencial 2020 - USA)',
    xaxis_title='Mes',
    yaxis_title='Total discursos',
    barmode='group',
    xaxis={'categoryorder': 'array', 'categoryarray': meses_ordenados}
)

fig_bar_total_mes.show()





# Filtrar los discursos del mes de septiembre y de tipo 'Campaign Speech'
campaign_speeches = df_speeches[
    (df_speeches['month_str'] == 'September') &
    (df_speeches['type'] == 'Campaign Speech')
]

# Obtener los top 5 speakers entre esos discursos
top_speakers = campaign_speeches['speaker'].value_counts().head(5).index

# Filtrar el DataFrame original por esos top speakers y tipo 'Campaign Speech' en septiembre
filter_data_mes = df_speeches[
    (df_speeches['speaker'].isin(top_speakers)) &
    (df_speeches['month_str'] == 'September') &
    (df_speeches['type'] == 'Campaign Speech')
].copy()

# Crear campos que separen la ciudad y el estado en dos nuevas columnas
filter_data_mes[['city', 'state']] = filter_data_mes['location'].str.split(', ', expand=True)
filter_data_mes


total_por_location = filter_data_mes.groupby('state').size().reset_index(name='total_discursos')

total_location=filter_data_mes.groupby('state').size().reset_index(name='total_discursos').sort_values('total_discursos', ascending=False)
total_location





#Visualización por día y mes

#Determinar el top 5 mandatarios con más discursos

top5_mandatarios = df_speeches['speaker'].value_counts().head(5).index.tolist()

# Filtrar sólo top 5
df_top5 = df_speeches[df_speeches['speaker'].isin(top5_mandatarios)].copy()

#  Asegurar que 'date' es datetime
df_top5['date'] = pd.to_datetime(df_top5['date'])

#  Agrupar por día y mandatario: contar discursos
df_grouped = df_top5.groupby(['date', 'speaker']).size().reset_index(name='count')

# Pivotear para cambiar la estructura del dateframe a efetos del gráfico
df_pivot = df_grouped.pivot(index='date', columns='speaker', values='count').fillna(0)

# Ordenar fechas y hacer acumulado (cumsum)
df_pivot = df_pivot.sort_index()
df_pivot.iloc[0] = 0  # primer valor en 0
df_pivot = df_pivot.cumsum().reset_index()

#  Melt para plotear
dfm = pd.melt(df_pivot, id_vars=['date'], value_vars=df_pivot.columns[1:])

# Plotly
fig = px.line(dfm, x="date", y="value", color="speaker")
fig.update_layout(xaxis=dict(tickformat="%d-%m"))

#Actualizar el gráfico
fig.update_layout(
    title='Cantidad de discursos acumulados del Top 5 mandatarios por día del mes (Campaña presidencial 2020 - USA)',
    xaxis_title='Día del mes',
    yaxis_title='Cantidad de discursos'
)
fig.show()










campaign_speeches = df_speeches[df_speeches['type'] == 'Campaign Speech']

# Obtener los top 5 speakers entre esos discursos
top_speakers = campaign_speeches['speaker'].value_counts().head(5).index

# Filtrar el DataFrame original por esos top speakers y tipo 'Campaign Speech'
df_speeches_top_5 = df_speeches[
    (df_speeches['speaker'].isin(top_speakers)) &
    (df_speeches['type'] == 'Campaign Speech')
]
df_speeches_top_5





def clean_text(df, column_name):
    
    result = df[column_name].str.replace(r"^[^\n]*\n", "", regex=True)

    # Eliminar texto entre \n...\n que contenga ":"
    result = result.str.replace(r'\n[^\n]*?:[^\n]*?\n', ' ', regex=True)

    # Eliminar lo que está entre corchetes incluidos los corchetes
    result = result.str.replace(r'\[.*?\]', '', regex=True)

    # Eliminar las horas entre paréntesis (y dejar un espacio)
    result = result.str.replace(r"\([^)]*\)", "", regex=True)

    # Reemplazar saltos de línea por espacio
    result = result.str.replace(r"\n", "", regex=True)

    # Convertir a minúsculas
    result = result.str.lower()

    # Eliminar signos de puntuación
    for punc in ["[", ",", ":", "?", ".", "…", "-", "“", "”", "‘", "]", "%"]:
        result = result.str.replace(re.escape(punc), "", regex=True)

    # Eliminar espacios múltiples
    result = result.str.replace(r'\s+', ' ', regex=True).str.strip()
    
    return result





df_speeches_top_5 = df_speeches_top_5.copy()
df_speeches_top_5["CleanText"] = clean_text(df_speeches_top_5,'text')
df_speeches_top_5





subset = df_speeches_top_5.iloc[1:6]
#  Mostrar CleanText completo de la primera fila del subset
#print(subset.iloc[0]["CleanText"])





df_speeches_top_5["WordList"] = df_speeches_top_5["CleanText"].str.split()





df_speeches_top_5['Word_Count'] = df_speeches_top_5['WordList'].apply(len)
df_speeches_top_5[['speaker','Word_Count']]





# Agrupar por speaker y sumar Word_Count
df_speeches_top5_total_palabras=df_speeches_top_5.groupby('speaker')['Word_Count'].sum().reset_index()

# Renombrar el campo WordCount por Total Words

df_speeches_top5_total_palabras.rename(columns={'Word_Count':'Total_Words'},inplace=True)



df_speeches_top5_total_palabras.sort_values("Total_Words", ascending=False)





# Boxplot múltiple para visualizar cantidad de palabras por candidato

sns.boxplot(data=df_speeches_top_5, x='speaker', y='Word_Count')

plt.title('Cantidad de palabras por candidato')
plt.xlabel('Candidato')
plt.ylabel('Cantidad de palabras')
plt.xticks(rotation=45) 
plt.tight_layout()
plt.show()





fig = px.bar(
    df_speeches_top5_total_palabras.sort_values("Total_Words", ascending=False),
    x="speaker",
    y="Total_Words",
    title="Total de palabras por orador y discurso de campaña (Elecciones USA -2020)",
    labels={"speaker": "Orador", "Total_Words": "Total de Palabras"},
    text="Total_Words"
)

fig.update_traces(textposition="outside")
fig.show()





def palabra_mas_frecuente(lista_palabras):
    contador=Counter(lista_palabras)
    palabra,cantidad=contador.most_common(1)[0]
    return pd.Series([palabra,cantidad],index=['Max_Word','Max_Word_Count'])

#Agrupar por speaker y sumar la lista
df_speeches_top_5_agrupado=df_speeches_top_5.groupby('speaker')['WordList'].sum().reset_index()

df_speeches_top_5_agrupado[['Max_Word','Max_Word_Count']]=df_speeches_top_5_agrupado['WordList'].apply(palabra_mas_frecuente)

df_speeches_top_5_agrupado.sort_values("Max_Word_Count",ascending=False)








fig = px.bar(
    df_speeches_top_5_agrupado,
    x='Max_Word_Count',
    y='speaker',
    text='Max_Word',
    labels={"speaker": "Orador", "Max_Word_Count": "Palabra que más se repite"},
    title="Palabra que más se repite en el discurso de campaña USA 2020"
)

fig.update_traces(textfont_size=12, textangle=0, textposition="outside", cliponaxis=False)
fig.show()





palabras_a_eliminar_con_pronombres = ['the','and','or','yes','no','as','also','actually','in','a','hi','for','is','hello','on','in','name','to','of','that','then','it','so','have','this',
                                      'are','about','biden','trump','bernie','sanders','donald','joe','our','but','harris','be','not','kamala','with','was','going','was','my','your','angela','will','we’re','it’s','all']

#Eliminando los pronombres
palabras_a_eliminar_sin_pronombres =['the', 'is', 'and', 'a', 'of', 'to', 'in', 'for', 'on', 'with', 'that', 'by', 'at','you','we','i', 'this', 'it', 'so', 'are', 'they','have', 'he','but','our','be', 'our','about','going','was','not','it’s','as','said','all','what','my']

# Drop de palabras dentro de las listas WordList
def limpiar_lista(lista):
    return [p.lower() for p in lista if p.lower() not in palabras_a_eliminar_sin_pronombres]


df_speeches_top_5_agrupado['WordList'] = df_speeches_top_5_agrupado['WordList'].apply(limpiar_lista)

# Función para obtener la palabra más frecuente y su conteo
def palabra_mas_frecuente(lista_palabras):
    contador = Counter(lista_palabras)
    palabra, cantidad = contador.most_common(1)[0]
    return pd.Series([palabra, cantidad], index=['Max_Word', 'Max_Word_Count'])

# Aplicar la función
df_speeches_top_5_agrupado[['Max_Word', 'Max_Word_Count']] = df_speeches_top_5_agrupado['WordList'].apply(palabra_mas_frecuente)

print(df_speeches_top_5_agrupado)


#Crear un gráfico que refleje cuantas veces se repite por mandatario
fig = go.Figure()

fig.add_trace(go.Bar(
    x=df_speeches_top_5_agrupado['speaker'],
    y=df_speeches_top_5_agrupado['Max_Word_Count'],
    text=df_speeches_top_5_agrupado['Max_Word'],
    textposition='outside',
    marker_color='steelblue'
))

fig.update_layout(
    title='Palabra más frecuente en los discursos de los mandatarios de las elecciones USA - 2020 (Top 5)',
    xaxis_title='Mandatarios',
    yaxis_title='Cantidad de repeticiones',
    yaxis=dict(tickformat=',d')
)

fig.show()



# Obtener los 5 candidatos más frecuentes
candidatos = df_speeches_top_5_agrupado['speaker'].value_counts().head(5).index

# Crear subplots
fig, axs = plt.subplots(1, len(candidatos), figsize=(20, 5))

# Generar una nube por cada candidato
for i, candidato in enumerate(candidatos):
    df_candidato = df_speeches_top_5_agrupado[df_speeches_top_5_agrupado['speaker'] == candidato]
    freqs = dict(zip(df_candidato['Max_Word'], df_candidato['Max_Word_Count']))
    
    wc = WordCloud(width=400, height=400, background_color='white', colormap='Greens').generate_from_frequencies(freqs)
    
    axs[i].imshow(wc, interpolation='bilinear')
    axs[i].axis('off')
    axs[i].set_title(candidato)

plt.tight_layout()
plt.show()




fig = px.scatter(df_speeches_top_5_agrupado,
                 x='speaker',
                 y=[0]*len(df_speeches_top_5_agrupado),  # para alinear en una sola línea
                 size='Max_Word_Count',
                 text='Max_Word',
                 size_max=60,
                 color='speaker')

fig.update_traces(textposition='top center')
fig.update_layout(title='Palabra más usada por cada mandatario (tamaño = frecuencia)',
                  yaxis=dict(showticklabels=False),
                  xaxis_title='Mandatario',
                  showlegend=False)

fig.show()





# TODO: Construya una matriz de 5x5, donde cada fila y columna corresponden a un candiato/a, 
# y la entrada (i,j) contiene la cantidad de veces que el candiato/a “i” menciona al candiato/a “j”.

speaker_to_lastname = {
    "Donald Trump": "trump",
    "Kamala Harris": "harris",
    "Mike Pence": "pence",
    "Joe Biden": "biden",
    "Bernie Sanders": "sanders"
}

# Filtrar solo los que te interesan
df_filtrado = df_speeches_top_5[df_speeches_top_5['speaker'].isin(speaker_to_lastname.keys())]

# Crear matriz vacía
matriz = pd.DataFrame(0, index=speaker_to_lastname.values(), columns=speaker_to_lastname.values())

# Recorrer cada discurso
for _, row in df_filtrado.iterrows():
    speaker_full = row['speaker']  
    words = row['WordList']          
    speaker_short = speaker_to_lastname[speaker_full]  
    
    # Contar menciones
    for mentioned in speaker_to_lastname.values():
        count = words.count(mentioned)
        matriz.loc[speaker_short, mentioned] += count

# Mostrar
print(matriz)



# mentions_matrix = ...

# Opcional: Genere un grafo dirigido con esa matriz de adyacencia para visualizar las menciones. 
# Puede ser util la biblioteca networkx






# Crear grafo dirigido
G = nx.DiGraph()

# Agregar nodos 
for nodo in matriz.index:
    G.add_node(nodo)

# Agregar aristas con pesos
for speaker in matriz.index:
    for mentioned in matriz.columns:
        weight = matriz.loc[speaker, mentioned]
        if weight > 0:
            G.add_edge(speaker, mentioned, weight=weight)

# Dibujar grafo
pos = nx.spring_layout(G, seed=42)  

# Dibujar nodos y etiquetas
nx.draw_networkx_nodes(G, pos, node_color='lightblue', node_size=1500)
nx.draw_networkx_labels(G, pos, font_size=10, font_weight='bold')

# Dibujar aristas con pesos
edges = G.edges(data=True)
nx.draw_networkx_edges(G, pos, edgelist=edges, arrowstyle='->', arrowsize=15, edge_color='gray')
edge_labels = {(u, v): d['weight'] for u, v, d in edges}
nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=9)

plt.title("Grafo de menciones entre mandatarios en discursos de campaña - USA 2020")
plt.axis('off')
plt.show()




