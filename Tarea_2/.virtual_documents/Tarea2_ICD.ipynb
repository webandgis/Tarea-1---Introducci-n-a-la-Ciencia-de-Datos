





import re
import os

from time import time
from pathlib import Path

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px

from nltk.corpus import stopwords
import nltk
import matplotlib.patches as mpatches
from sklearn.model_selection import cross_val_score
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import make_pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline











url='https://raw.githubusercontent.com/webandgis/csv_ICD_speeches/refs/heads/main/us_2020_election_speeches.csv'
df_speeches= pd.read_csv(url)
df_speeches





def clean_text(df, column_name):

    result = df[column_name].str.replace(r"^[^\n]*\n", "", regex=True)

    # Eliminar texto entre \n...\n que contenga ":"
    result = result.str.replace(r'\n[^\n]*?:[^\n]*?\n', ' ', regex=True)

    # Eliminar lo que está entre corchetes incluidos los corchetes
    result = result.str.replace(r'\[.*?\]', '', regex=True)

    # Eliminar las horas entre paréntesis (y dejar un espacio)
    result = result.str.replace(r"\([^)]*\)", "", regex=True)

    # Reemplazar saltos de línea por espacio
    result = result.str.replace(r"\n", "", regex=True)

    # Convertir a minúsculas
    result = result.str.lower()

    # Eliminar signos de puntuación
    for punc in ["[", ",", ":", "?", ".", "…", "-", "“", "”", "‘", "]", "%"]:
        result = result.str.replace(re.escape(punc), "", regex=True)

    # Eliminar espacios múltiples
    result = result.str.replace(r'\s+', ' ', regex=True).str.strip()

    return result





campaign_speeches = df_speeches[df_speeches['type'] == 'Campaign Speech']

# Obtener los top 3 speakers entre esos discursos
top_speakers = campaign_speeches['speaker'].value_counts().head(3).index

# Filtrar por top 3 speakers y tipo de discurso 'Campaign Speech'
df_speeches_top_3= df_speeches[
    (df_speeches['speaker'].isin(top_speakers)) &
    (df_speeches['type'] == 'Campaign Speech')
]
df_speeches_top_3





df_speeches_top_3 = df_speeches_top_3.copy()
df_speeches_top_3["CleanText"] = clean_text(df_speeches_top_3,'text')
df_speeches_top_3





# 1: Separar 30% del conjunto para test. Al resto lo llamamos "dev" (desarrollo).

# X_dev, X_test, y_dev, y_test = ...
X = df_speeches_top_3['CleanText']
y = df_speeches_top_3['speaker']

# Dividir el dataset en 70% train/dev y 30% test con muestreo estratificado
X_dev, X_test, y_dev, y_test = train_test_split(
    X,
    y,
    test_size=0.3,
    stratify=y,
    random_state=42
)

# Mostrar tamaños
print(f"Tamaños de los conjuntos:")
print(f"X_dev: {X_dev.shape}, X_test: {X_test.shape}")
print(f"y_dev: {y_dev.shape}, y_test: {y_test.shape}")



# 2: Visualización de la proporción de cada candidato por conjunto
# Crear DataFrame con y_dev y y_test etiquetados
df_dev = pd.DataFrame({'speaker': y_dev, 'set': 'Train/Dev'})
df_test = pd.DataFrame({'speaker': y_test, 'set': 'Test'})

# Combinar ambos conjuntos
df_combined = pd.concat([df_dev, df_test])

# Calcular proporción de discursos por candidato en cada conjunto
speaker_counts = (
    df_combined
    .groupby(['set', 'speaker'])
    .size()
    .reset_index(name='count')
)

# Calcular proporciones
total_counts = speaker_counts.groupby('set')['count'].transform('sum')
speaker_counts['proportion'] = speaker_counts['count'] / total_counts

# Gráfico con plotly
fig = px.bar(
    speaker_counts,
    x='speaker',
    y='proportion',
    color='set',
    barmode='group',
    text='proportion',
    labels={'speaker': 'Candidato', 'proportion': 'Proporción'},
    title='Proporción de discursos por candidato en Train/Dev y Test'
)

fig.update_traces(texttemplate='%{text:.2%}', textposition='outside')
fig.update_layout(yaxis_tickformat='.0%', uniformtext_minsize=8, uniformtext_mode='hide')
fig.show()



# 3: Transforme el texto del conjunto de entrenamiento a la representación numérica (features) de conteo de palabras o bag of words.

# tokenización, conteo y creación de la matriz de conteo de palabras
count_vect = CountVectorizer()
X_dev_bow = count_vect.fit_transform(X_dev)

print("\nTamaño de la matriz BoW del conjunto de entrenamiento:")
print(f"{X_dev_bow.shape[0]} documentos, {X_dev_bow.shape[1]} palabras únicas (features)")


#por ejemplo para ver la cantidad de palabras diferentes que tiene el 1er discurso o documento
X_dev_bow[0]



print(X_dev_bow[0])
#el número de la derecha representa la cantidad de veces que aperece la palabra de la columna mencionada


#para ver la proporción de valores no nulos en la primera fila
proporcion_fila0 = X_dev_bow[0].nnz / X_dev_bow.shape[1]
print(f"Proporción primera fila: {proporcion_fila0:.4f}")

#para ver la proporción de valores no nulos en toda la matriz
proporcion_total = X_dev_bow.nnz / (X_dev_bow.shape[0] * X_dev_bow.shape[1])
print(f"Proporción total matriz: {proporcion_total:.4f}")



# 4: Obtenga la representación numérica Term Frequency - Inverse Document Frequency.

# Crear el vectorizador TF-IDF con n-gramas (ej: bigramas y unigramas)
vectorizer = TfidfVectorizer(ngram_range=(1, 2))

# Ajustar y transformar el conjunto de entrenamiento
X_dev_tfidf = vectorizer.fit_transform(X_dev)

# Transformar el conjunto de test (sin ajustar nuevamente)
X_test_tfidf = vectorizer.transform(X_test)

# Mostrar dimensiones y vocabulario
print(f"Shape de la matriz TF-IDF: {X_dev_tfidf.shape}")
print(f"Cantidad de términos (incluyendo n-gramas): {len(vectorizer.vocabulary_)}")



# 5 :Muestre en un mapa el conjunto de entrenamiento, utilizando las dos primeras componentes PCA sobre los vectores de tf-idf.
def plot_pca_tfidf(X_text, y_labels, stop_words=None, use_idf=True, ngram_range=(1,2), title='PCA TF-IDF'):
    # Crear vectorizador TF-IDF con parámetros dados
    vectorizer = TfidfVectorizer(stop_words=stop_words, use_idf=use_idf, ngram_range=ngram_range)

    # Ajustar y transformar texto
    X_tfidf = vectorizer.fit_transform(X_text)

    # PCA a 2 componentes
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X_tfidf.toarray())  # convertir matriz dispersa a densa

    # Crear DataFrame para graficar
    df = pd.DataFrame({
        'PCA1': X_pca[:, 0],
        'PCA2': X_pca[:, 1],
        'speaker': y_labels
    })

    # Plot con seaborn
    plt.figure(figsize=(8, 5))
    sns.scatterplot(data=df, x='PCA1', y='PCA2', hue='speaker', palette='tab10', s=60, alpha=0.7)
    plt.title(title)
    plt.xlabel('Componente Principal 1')
    plt.ylabel('Componente Principal 2')
    plt.legend(title='Orador', bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout()
    plt.show()





# Sin filtrado de stop words, unigrama, use_idf=True (default)
plot_pca_tfidf(X_dev, y_dev, stop_words=None, use_idf=False, ngram_range=(1,1),
               title='PCA (sin filtrado de stop words, unigramas)')

# Sin filtrado de stop words, unigrama, use_idf=True (default)
plot_pca_tfidf(X_dev, y_dev, stop_words=None, use_idf=True, ngram_range=(1,1),
               title='PCA TF-IDF (sin filtrado de stop words, unigramas)')

# Sin filtrado de stop words, unigrama, use_idf=True (default)
plot_pca_tfidf(X_dev, y_dev, stop_words=None, use_idf=True, ngram_range=(1,2),
               title='PCA TF-IDF (sin filtrado de stop words, unigramas y bigramas)')

# con filtrado de stop words inglés, unigramas, use_idf=True
plot_pca_tfidf(X_dev, y_dev, stop_words='english', use_idf=True, ngram_range=(1,1),
               title='PCA TF-IDF (con filtrado de stop words inglés, unigramas)')

# con filtrado de stop words inglés, bigramas + unigramas, use_idf=True
plot_pca_tfidf(X_dev, y_dev, stop_words='english', use_idf=True, ngram_range=(1,2),
               title='PCA TF-IDF (con filtrado de stop words inglés, unigramas y bigramas)')



#OPCIONAL
# Vectorizador sin signos de puntuación (default)
vectorizer_sin_puntuacion = TfidfVectorizer(stop_words='english', use_idf=True, ngram_range=(1,2))

# Vectorizador con signos de puntuación
vectorizer_con_puntuacion = TfidfVectorizer(
    stop_words='english',
    use_idf=True,
    ngram_range=(1,2),
    token_pattern=r"(?u)\b\w+\b")  # Este patrón excluye puntuación


# Utilizar'analyzer="char"' para que considere caracteres individuales, incluidos signos:
vectorizer_con_puntuacion = TfidfVectorizer(
    stop_words='english',
    use_idf=True,
    ngram_range=(1,2),
    analyzer='char_wb',  # usa caracteres dentro de ventana para captar puntuación
)


#OPCIONAL
# Vectorizadores
vectorizer_sin_puntuacion = TfidfVectorizer(stop_words='english', use_idf=True, ngram_range=(1,2))
vectorizer_con_puntuacion = TfidfVectorizer(stop_words='english', use_idf=True, ngram_range=(1,2), analyzer='char_wb')

def pca_plotly_scatter(X_text, y_labels, vectorizer, title):
    # Vectorizar texto
    X_tfidf = vectorizer.fit_transform(X_text)

    # PCA 2D
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X_tfidf.toarray())

    # Crear dataframe para plotly
    df_pca = pd.DataFrame({
        'PCA1': X_pca[:,0],
        'PCA2': X_pca[:,1],
        'Speaker': y_labels
    })

    fig = px.scatter(df_pca, x='PCA1', y='PCA2', color='Speaker',
                     title=title, labels={'PCA1':'PCA Componente 1', 'PCA2':'PCA Componente 2'},
                     width=800, height=600)
    fig.show()

    return X_tfidf

def plot_variance_explained(X_tfidf, title):
    pca = PCA(n_components=10)
    pca.fit(X_tfidf.toarray())
    varianza_acum = np.cumsum(pca.explained_variance_ratio_)

    plt.figure(figsize=(8,5))
    plt.plot(range(1, 11), varianza_acum, marker='o', linestyle='--')
    plt.title(title)
    plt.xlabel('Número de componentes principales')
    plt.ylabel('Varianza explicada acumulada')
    plt.xticks(range(1, 11))
    plt.grid(True)
    plt.show()

# Ejecutar con sin puntuación
X_tfidf_sin_puntuacion = pca_plotly_scatter(X_dev, y_dev, vectorizer_sin_puntuacion, "PCA 2D - TF-IDF sin puntuación")
plot_variance_explained(X_tfidf_sin_puntuacion, "Varianza explicada acumulada - TF-IDF sin puntuación")

# Ejecutar con puntuación
X_tfidf_con_puntuacion = pca_plotly_scatter(X_dev, y_dev, vectorizer_con_puntuacion, "PCA 2D - TF-IDF con puntuación")
plot_variance_explained(X_tfidf_con_puntuacion, "Varianza explicada acumulada - TF-IDF con puntuación")


#ACÁ ES EL GRÁFICO SIN ACUMULAR, VARIANZA EXPLICADA POR COMPONENTE
# Haga una visualización que permita entender cómo varía la varianza explicada a medida que se agregan componentes (e.g: hasta 10 componentes).

# PCA con hasta 10 componentes
n_components = 10
pca = PCA(n_components=n_components)
X_dev_tfidf_pca = pca.fit_transform(X_dev_tfidf.toarray())

# Gráfico de varianza explicada
plt.figure(figsize=(8, 5))
plt.plot(range(1, n_components + 1), pca.explained_variance_ratio_, marker='o')
plt.xlabel('Número de Componentes Principales')
plt.ylabel('Varianza Explicada')
plt.title('Varianza Explicada por Componentes PCA')
plt.grid(True)
plt.xticks(range(1, n_components + 1))
plt.show()

print(vectorizer.stop_words)
print(vectorizer.use_idf)
print(vectorizer.ngram_range)


# PCA con hasta 10 componentes
n_components = 10
pca = PCA(n_components=n_components)
X_dev_tfidf_pca = pca.fit_transform(X_dev_tfidf.toarray())

# Varianza explicada y acumulada
varianza_explicada = pca.explained_variance_ratio_
varianza_acumulada = np.cumsum(varianza_explicada)

# Gráfico combinado
plt.figure(figsize=(8, 5))
plt.plot(range(1, n_components + 1), varianza_explicada, marker='o', label='Varianza explicada')
plt.plot(range(1, n_components + 1), varianza_acumulada, marker='s', label='Varianza acumulada')
plt.xlabel('Número de Componentes Principales')
plt.ylabel('Proporción de Varianza')
plt.title('Varianza Explicada y Acumulada por Componentes PCA')
plt.legend()
plt.grid(True)
plt.xticks(range(1, n_components + 1))
plt.ylim(0, 1.05)
plt.show()

print(vectorizer.stop_words)  # None si no se filtraron
print(vectorizer.use_idf)     # True por defecto
print(vectorizer.ngram_range)  # (1, 2)








def clean_text_con_signos_puntuacion(df, column_name):

    result = df[column_name].str.replace(r"^[^\n]*\n", "", regex=True)

    # Eliminar texto entre \n...\n que contenga ":"
    result = result.str.replace(r'\n[^\n]*?:[^\n]*?\n', ' ', regex=True)

    # Eliminar lo que está entre corchetes incluidos los corchetes
    result = result.str.replace(r'\[.*?\]', '', regex=True)

    # Eliminar las horas entre paréntesis (y dejar un espacio)
    result = result.str.replace(r"\([^)]*\)", "", regex=True)

    # Reemplazar saltos de línea por espacio
    result = result.str.replace(r"\n", "", regex=True)

    # Convertir a minúsculas
    result = result.str.lower()

    return result





df_speeches_top_3_csp = df_speeches_top_3.copy()
df_speeches_top_3_csp["CleanTextCSP"] = clean_text_con_signos_puntuacion(df_speeches_top_3_csp,'text')
df_speeches_top_3_csp





# X_dev, X_test, y_dev, y_test = ...
X_csp = df_speeches_top_3_csp['CleanTextCSP']
y_csp = df_speeches_top_3_csp['speaker']

# Dividir el dataset en 70% train/dev y 30% test con muestreo estratificado
X_dev_csp, X_test_csp, y_dev_csp, y_test_csp = train_test_split(
    X_csp,
    y_csp,
    test_size=0.3,
    stratify=y_csp,
    random_state=42
)

# Mostrar tamaños
print(f"Tamaños de los conjuntos:")
print(f"X_dev_csp: {X_dev_csp.shape}, X_test_csp: {X_test_csp.shape}")
print(f"y_dev_csp: {y_dev_csp.shape}, y_test_csp: {y_test_csp.shape}")






# Vectorizadores
vectorizer_sin_puntuacion = TfidfVectorizer(stop_words='english', use_idf=True, ngram_range=(1,2))
vectorizer_con_puntuacion = TfidfVectorizer(stop_words='english', use_idf=True, ngram_range=(1,2), analyzer='char_wb')

# Función para graficar PCA en Plotly
def pca_plotly_scatter(X_text, y_labels, vectorizer, title):
    # Vectorizar texto
    X_tfidf = vectorizer.fit_transform(X_text)

    # PCA 2D
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X_tfidf.toarray())

    # Crear dataframe para plotly
    df_pca = pd.DataFrame({
        'PCA1': X_pca[:,0],
        'PCA2': X_pca[:,1],
        'Speaker': y_labels.values  # <- Asegurar que es compatible con el DataFrame
    })

    fig = px.scatter(df_pca, x='PCA1', y='PCA2', color='Speaker',
                     title=title, labels={'PCA1':'PCA Componente 1', 'PCA2':'PCA Componente 2'},
                     width=800, height=600)
    fig.show()

    return X_tfidf

# Función para graficar varianza explicada acumulada
def plot_variance_explained(X_tfidf, title):
    pca = PCA(n_components=10)
    pca.fit(X_tfidf.toarray())
    varianza_acum = np.cumsum(pca.explained_variance_ratio_)

    plt.figure(figsize=(8,5))
    plt.plot(range(1, 11), varianza_acum, marker='o', linestyle='--')
    plt.title(title)
    plt.xlabel('Número de componentes principales')
    plt.ylabel('Varianza explicada acumulada')
    plt.xticks(range(1, 11))
    plt.grid(True)
    plt.show()

# Ejecutar  sin puntuación
X_tfidf_sin_puntuacion = pca_plotly_scatter(X_dev, y_dev, vectorizer_sin_puntuacion, "PCA 2D - TF-IDF sin puntuación")
plot_variance_explained(X_tfidf_sin_puntuacion, "Varianza explicada acumulada - TF-IDF sin puntuación")

# Ejecutar con puntuación
X_tfidf_con_puntuacion = pca_plotly_scatter(X_dev_csp, y_dev_csp, vectorizer_con_puntuacion, "PCA 2D - TF-IDF con puntuación")
plot_variance_explained(X_tfidf_con_puntuacion, "Varianza explicada acumulada - TF-IDF con puntuación")















# Genere una visualización que permita comparar las métricas (e.g: accuracy) de los distintos modelos entrenados, viendo el valor promedio y variabilidad de las mismas en todos los splits (e.g: en un gráfico de violín).
# 1. Vectorizar los datos
vectorizer = TfidfVectorizer(stop_words='english', use_idf=True, ngram_range=(1, 2))
X_dev_tfidf = vectorizer.fit_transform(X_dev)
X_test_tfidf = vectorizer.transform(X_test)

# 2. Entrenar el modelo
model = MultinomialNB()
model.fit(X_dev_tfidf, y_dev)

# 3. Predecir
y_pred = model.predict(X_test_tfidf)

# 4. Mostrar matriz de confusión
ConfusionMatrixDisplay.from_predictions(
    y_test, y_pred,
    display_labels=model.classes_,
    cmap='Greens',
    xticks_rotation=45
)
plt.title("Matriz de Confusión - Naive Bayes")
plt.xlabel("Etiqueta Predicha (y_pred)" )
plt.ylabel("Etiqueta Verdadera (y_test)")
plt.show()

# 5. Otras métricas
print(f"\nAccuracy: {accuracy_score(y_test, y_pred):.4f}")
print("\nReporte de clasificación:\n")
print(classification_report(y_test, y_pred))


#A VERSIÓN DE VIOLINES USANDO GridSearchCV.
# 2: Implemente una búsqueda de hiperparámetros usando GridSearchCV.
# Crear pipeline: vectorizador + clasificador
pipeline = Pipeline([
    ('vect', TfidfVectorizer(stop_words='english')),
    ('clf', MultinomialNB())
])

# Definir grilla de hiperparámetros
param_grid = {
    'vect__ngram_range': [(1, 1), (1, 2)],
    'vect__use_idf': [True],
    'clf__alpha': [0.5, 1.0, 2.0]
}

# GridSearch con validación cruzada (cv=5)
grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', return_train_score=False)
grid.fit(X_dev, y_dev)

# Obtener resultados
results = pd.DataFrame(grid.cv_results_)

# Preparar datos para gráfico
resultados = []
for mean, std, params in zip(results['mean_test_score'], results['std_test_score'], results['params']):
    for score in grid.cv_results_['split0_test_score'], grid.cv_results_['split1_test_score'], \
                 grid.cv_results_['split2_test_score'], grid.cv_results_['split3_test_score'], \
                 grid.cv_results_['split4_test_score']:
        resultados.append({
            'accuracy': score[results.index[results['params'] == params][0]],
            'config': f"ngrams={params['vect__ngram_range']}, idf={params['vect__use_idf']}, alpha={params['clf__alpha']}"
        })

df_resultados = pd.DataFrame(resultados)

# Gráfico de violín
fig = px.violin(df_resultados,
                y='accuracy',
                x='config',
                box=True,
                points='all',
                title='Distribución de Accuracy por Configuración (GridSearchCV)',
                labels={'accuracy': 'Accuracy', 'config': 'Configuración'},
                color='config')

fig.update_layout(xaxis_tickangle=-45, height=600)
fig.show()



# 3: Elija el mejor modelo (mejores parámetros) y vuelva a entrenar sobre todo el conjunto de entrenamiento disponible (sin quitar datos para validación). Reporte el valor final de las métricas y la matriz de confusión.
# 1. Calcular el promedio de accuracy por configuración
promedios = df_resultados.groupby("config")["accuracy"].mean().sort_values(ascending=False)

# 2. Mostrar la mejor configuración
print("Esta es la mejor configuración:")
print(promedios.head(1))

# 3. Extraer nombre de la mejor configuración (asumiendo que es un string como: "ngrams=(1,1), idf=True, alpha=1.0")
mejor_config = promedios.index[0]

# 4. Interpretar la configuración para reentrenar el modelo

import re

# Extraer parámetros
ngrams = tuple(map(int, re.search(r"ngrams=\((\d),\s*(\d)\)", mejor_config).groups()))
use_idf = "idf=True" in mejor_config
alpha = float(re.search(r"alpha=([\d.]+)", mejor_config).group(1))

# 5. Entrenar el mejor modelo con todos los datos de entrenamiento
modelo_final = make_pipeline(
    TfidfVectorizer(ngram_range=ngrams, use_idf=use_idf, stop_words='english'),
    MultinomialNB(alpha=alpha)
)
modelo_final.fit(X_dev, y_dev)

# 6. Evaluar en el conjunto de test
y_pred = modelo_final.predict(X_test)

# 7. Reportar métricas finales
print("\nReporte de clasificación final:")
print(classification_report(y_test, y_pred))

print("Matriz de confusión:")
print(confusion_matrix(y_test, y_pred))


# 4: Evalúe con validación cruzada al menos un modelo más (dentro de scikit-learn) aparte de Multinomial Naive Bayes para clasificar el texto utilizando las mismas features de texto.
# Crear pipeline con Logistic Regression

modelo_logreg = make_pipeline(
    TfidfVectorizer(ngram_range=(1, 1), use_idf=True, stop_words='english'),
    LogisticRegression(max_iter=1000, random_state=42)
)

# Validación cruzada (5-fold)
cv_scores = cross_val_score(modelo_logreg, X_dev, y_dev, cv=5, scoring='accuracy')
print(f"Accuracy promedio con validación cruzada (Logistic Regression): {np.mean(cv_scores):.2f}")
print(f"Accuracy por fold: {cv_scores}")

# Entrenar con conjunto de entrenamiento completo
modelo_logreg.fit(X_dev, y_dev)

# Predecir sobre el test
y_pred_logreg = modelo_logreg.predict(X_test)

# Accuracy
acc = accuracy_score(y_test, y_pred_logreg)
print(f"\nAccuracy final en test (Logistic Regression): {acc:.2f}")

# Matriz de confusión
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_logreg)

# Métricas detalladas
print("\nClassification Report:")
print(classification_report(y_test, y_pred_logreg))


# 4: Evalúe con validación cruzada al menos un modelo más (dentro de scikit-learn) aparte de Multinomial Naive Bayes para clasificar el texto utilizando las mismas features de texto.

# Crear pipeline con logistic regression
modelo_logreg = make_pipeline(
    TfidfVectorizer(ngram_range=(1, 1), use_idf=True, stop_words='english'),
    LogisticRegression(max_iter=1000, random_state=42)
)

# Validación cruzada sobre conjunto de desarrollo
cv_scores = cross_val_score(modelo_logreg, X_dev, y_dev, cv=5, scoring='accuracy')
print(f"Accuracy promedio (CV=5): {cv_scores.mean():.2f}")
print(f"Accuracies por fold: {cv_scores}")

# Entrenar en todo el dev y predecir sobre test
modelo_logreg.fit(X_dev, y_dev)
y_pred_logreg = modelo_logreg.predict(X_test)

# Evaluación sobre test
acc = accuracy_score(y_test, y_pred_logreg)
print(f"\nAccuracy en test: {acc:.2f}")

# Matriz de confusión
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_logreg)

# Reporte de clasificación
print("\nReporte de clasificación(Test):")
print(classification_report(y_test, y_pred_logreg))


# Crear pipeline con regresión logística (sin validación cruzada)
modelo_logreg = make_pipeline(
    TfidfVectorizer(ngram_range=(1, 1), use_idf=True, stop_words='english'),
    LogisticRegression(max_iter=1000, random_state=42)
)

# Entrenar modelo con conjunto de desarrollo
modelo_logreg.fit(X_dev, y_dev)

# Predecir sobre el conjunto de test
y_pred_logreg = modelo_logreg.predict(X_test)

# Evaluar desempeño
acc = accuracy_score(y_test, y_pred_logreg)
print(f"\nAccuracy en test (Regresión Logística): {acc:.2f}")

# Mostrar matriz de confusión
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_logreg)
plt.title("Matriz de Confusión - Regresión Logística")
plt.xlabel("Etiqueta Verdadera")
plt.ylabel("Etiqueta Predicha")
plt.xticks(rotation=45)
plt.show()

# Reporte de clasificación
print("\nReporte de clasificación (Test):")
print(classification_report(y_test, y_pred_logreg))


# 5: Evalúe el problema cambiando al menos un candidato. En particular, observe el (des)balance de datos y los problemas que pueda generar, así como cualquier indicio que pueda ver en el mapeo previo con PCA.
print("Distribución en entrenamiento:")
print(y_dev.value_counts())

print("\nDistribución en test:")
print(y_test.value_counts())

# Filtrar solo discursos de Biden y Trumo
filtro = df_speeches_top_3['speaker'].isin(['Joe Biden','Donald Trump'])
df_filtrado = df_speeches_top_3[filtro]

# Repetir partición y procesamiento
X = df_filtrado['CleanText']
y = df_filtrado['speaker']

# 4. Dividir en train/test con estratificación
X_dev, X_test, y_dev, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# 5. Vectorizar con TF-IDF (unigramas + bigramas, stopwords, idf)
vectorizer = TfidfVectorizer(ngram_range=(1, 1), stop_words='english', use_idf=True)
X_dev_tfidf = vectorizer.fit_transform(X_dev)
X_test_tfidf = vectorizer.transform(X_test)

# 6. Entrenar el modelo
modelo = MultinomialNB()
modelo.fit(X_dev_tfidf, y_dev)

# 7. Predecir
y_pred = modelo.predict(X_test_tfidf)

# 8. Evaluar
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\n Reporte de clasificación:\n")
print(classification_report(y_test, y_pred))

# 9. Matriz de confusión (visual)
ConfusionMatrixDisplay.from_predictions(y_test, y_pred)
plt.title("Matriz de confusión - Test set")
plt.show()




# OPCIONAL: Repetir la clasificación con los tres candidatos con más discursos, pero esta vez clasificando a nivel de párrafos y no de discursos enteros.

# 1. Filtrar discursos de Trump y Biden
filtro = df_speeches_top_3['speaker'].isin(['Donald Trump', 'Joe Biden','Mike Pence'])
df_filtrado = df_speeches_top_3[filtro]

# 2. Dividir cada discurso en párrafos
parrafos = []
oradores = []

for _, row in df_filtrado.iterrows():
    texto = row['CleanText']
    speaker = row['speaker']

    # Separar por salto de línea doble o simple según el formato (ajustar si es necesario)
    for p in texto.split('\n'):
        p = p.strip()
        if len(p) > 30:  # ignorar párrafos muy cortos o vacíos
            parrafos.append(p)
            oradores.append(speaker)

# 3. Crear nuevo DataFrame a nivel de párrafos
df_parrafos = pd.DataFrame({'paragraph': parrafos, 'speaker': oradores})

# 4. Partición train/test estratificada
X = df_parrafos['paragraph']
y = df_parrafos['speaker']

X_dev, X_test, y_dev, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# Mostrar distribución
print("Distribución en entrenamiento:")
print(y_dev.value_counts())

print("\nDistribución en test:")
print(y_test.value_counts())

# 5. Vectorización TF-IDF
vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english', use_idf=True)
X_dev_tfidf = vectorizer.fit_transform(X_dev)
X_test_tfidf = vectorizer.transform(X_test)

# 6. Entrenamiento
modelo = MultinomialNB()
modelo.fit(X_dev_tfidf, y_dev)

# 7. Predicción
y_pred = modelo.predict(X_test_tfidf)

# 8. Evaluación
print("\nAccuracy:", accuracy_score(y_test, y_pred))
print("\nReporte de clasificación:\n")
print(classification_report(y_test, y_pred))

# 9. Matriz de confusión visual
ConfusionMatrixDisplay.from_predictions(y_test, y_pred)
plt.title("Matriz de confusión - Párrafos")
plt.show()


