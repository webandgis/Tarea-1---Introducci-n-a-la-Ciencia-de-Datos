





from time import time
from pathlib import Path
from wordcloud import WordCloud
import matplotlib.pyplot as plt

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx

# Agregue aqui el resto de las librerias que necesite
from dash import Dash, dcc, html, Input, Output
from collections import Counter
import plotly.graph_objects as go
import plotly.express as px
import numpy as np
import re

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import nltk



#### Descargar wordcloud para generar gráfico de palabra más frecuente


get_ipython().getoutput("pip install wordcloud")





# DataFrame con todos los discursos:
df_speeches = pd.read_csv("../data/us_2020_election_speeches.csv")
df_speeches





df_speeches.describe()





df_speeches.isnull().sum()





lista_filas_faltantes=df_speeches[df_speeches.isnull().any(axis=1)].index.tolist()
print('Las filas con datos null son las siguientes:',lista_filas_faltantes)
print('El número total de filas con datos faltantes es de:',len(lista_filas_faltantes))





#Identificar los valores nulls por campo de cada fila

lista_campos_nulls=df_speeches[df_speeches.isnull().any(axis=1)]

for i,row in lista_campos_nulls.iterrows():
  columnas_nulls=row[row.isnull()].index.tolist()
  print(f"Fila {i}:{', '.join(columnas_nulls)}")





df_speeches['speaker'].unique()





df_speeches['date'].unique()





df_speeches['location'].unique()





df_speeches['type'].unique()











df_speeches_top_5=df_speeches['speaker'].value_counts().head(5)
df_speeches_top_5





camp_speeches = df_speeches[df_speeches['type'] == 'Campaign Speech']

# Top speakers por discurso de campaña
df_speeches_top_5 = camp_speeches['speaker'].value_counts().head(5)

print(df_speeches_top_5)





# Convertir primero todo el campo speaker en str
df_speeches['speaker'] = df_speeches['speaker'].astype(str)
#Identificar los que están separadps por , lo cual indica hau mas de un orador
df_multiple_speakers = df_speeches[df_speeches['speaker'].str.contains(',')]
#Mostrar el data frame
df_multiple_speakers





#Crear un for para recorrer los speakers que están en el top 5 y sumarle si están en la variable de multiples oradores

for speaker in df_speeches_top_5.index:
     # Contar cuántas veces aparece el orador en la variable con múltiples oradores
    count_multiple_speakers=df_multiple_speakers['speaker'].str.contains(speaker).sum()

    #Asegurarse de contarlo una sola vez
    count_one_speaker=df_speeches[df_speeches['speaker']==speaker].shape[0]

    #Contar los multiples y unicos speakers
    df_speeches_top_5[speaker]= count_one_speaker + count_multiple_speakers

print(df_speeches_top_5)








# Separar las fechas por dia, mes y año
df_speeches['date'] = pd.to_datetime(df_speeches['date'], format='%b %d, %Y', errors='coerce')
df_speeches['date']=pd.to_datetime(df_speeches['date'])
df_speeches['year']=df_speeches['date'].dt.year
df_speeches['month']=df_speeches['date'].dt.month
df_speeches['day']=df_speeches['date'].dt.day
df_speeches['month_str']=df_speeches['date'].dt.month_name(locale='en_US')


## Visualizaciones 1 - Visualización por mes total (Solo discursos individuales)

#Ordenar la lista con los meses
meses_ordenados=['January', 'February','March','April','May','June','July','August','September','October']

#Identificar el top 5 mandatarios con más discursos
top5_mandatarios=df_speeches['speaker'].value_counts().head(5).index.tolist()

#Filtrar del dataframe orifinal el top 5 de mandatarios
df_top5=df_speeches[df_speeches['speaker'].isin(top5_mandatarios)]

#Convertir el mes en una categoría del gráfico
df_top5.loc[:,'month_str']=pd.Categorical(df_top5['month_str'],categories=meses_ordenados)

#Agrupar los mantararios y el mes de sus discursos
discursos_por_mes=df_top5.groupby(['speaker','month_str']).size().reset_index(name='total_discursos')

#Crear gráfico

fig_bar_total_mes=go.Figure()

for speaker in top5_mandatarios:
    df_speaker=discursos_por_mes[discursos_por_mes['speaker']==speaker]
    fig_bar_total_mes.add_trace(go.Bar(x=df_speaker['month_str'],
                                      y=df_speaker['total_discursos'],name=speaker))
#Configurar el layout del gráfico
fig_bar_total_mes.update_layout(
    title='Total discursos por mes del Top 5 mandatarios con mayor cantidad de discursos (Campaña presidencial 2020 - USA)',
    xaxis_title='Mes',
    yaxis_title='Total discursos',
    barmode='group',
    xaxis={'categoryorder': 'array', 'categoryarray': meses_ordenados}
)

fig_bar_total_mes.show()



# Top 5 mandatarios
top5_mandatarios = ['Joe Biden', 'Donald Trump', 'Mike Pence', 'Bernie Sanders', 'Kamala Harris']

# Mapeo de colores por partido
colores_partido = {
    'Joe Biden': 'blue',         
    'Donald Trump': 'red',         
    'Mike Pence': 'darkred',      
    'Bernie Sanders': 'green',    
    'Kamala Harris': 'darkblue'     
}

# Filtrar solo discursos del nuevo top 5
df_top5 = df_speeches[df_speeches['speaker'].isin(top5_mandatarios)]

# Agrupar por mes y mandatario
df_top5_grouped = df_top5.groupby([df_top5['date'].dt.to_period('M'), 'speaker']).size().reset_index(name='frecuencia')
df_top5_grouped['date'] = df_top5_grouped['date'].dt.to_timestamp()

# Gráfico 
fig = px.line(
    df_top5_grouped,
    x='date',
    y='frecuencia',
    color='speaker',
    markers=True,
    title="Discursos top 5 candidatos con más discursos a lo largo del tiempo (Campaña presidencial 2020 - USA)",
    labels={'date': 'Fecha', 'frecuencia': 'Cantidad de discursos', 'speaker': 'Candidato'},
    color_discrete_map=colores_partido
)

fig.update_layout(
    xaxis=dict(tickformat="%b %Y"),
    hovermode='x unified',
    template='plotly_white'
)

fig.show()



#Identificar el top 5 mandatarios con más discursos
top5_mandatarios=df_speeches['speaker'].value_counts().head(5).index.tolist()

#Filtrar del dataframe orifinal el top 5 de mandatarios
df_top5=df_speeches[df_speeches['speaker'].isin(top5_mandatarios)]

# Diccionario con colores por candidato
colores_partido = {
    'Joe Biden': 'darkblue',         
    'Donald Trump': 'red',         
    'Mike Pence': 'darkred',      
    'Bernie Sanders': 'green',    
    'Kamala Harris': 'blue'     
}

# Crear figura
plt.figure(figsize=(12, 6))

# Dibujar una línea por cada candidato, en orden del top 5
for candidato in top5_mandatarios:
    df_candidato = df_top5_grouped[df_top5_grouped['speaker'] == candidato]
    plt.plot(df_candidato['date'], df_candidato['frecuencia'],
             marker='o', label=candidato, color=colores_partido[candidato])

# Personalizar gráfico
plt.title("Discursos del top 5 candidatos con mayor número de discursos (Campaña presidencial 2020 - USA)")
plt.xlabel("Fecha")
plt.ylabel("Cantidad de discursos")
plt.xticks(rotation=45)
plt.legend(title='Candidato')
plt.tight_layout()
plt.savefig("discursos_candidatos_tiempo.png", dpi=300)
plt.show()





# Filtrar los discursos del mes de septiembre y de tipo 'Campaign Speech'
campaign_speeches = df_speeches[
    (df_speeches['month_str'] == 'September') &
    (df_speeches['type'] == 'Campaign Speech')
]

# Obtener los top 5 speakers entre esos discursos
top_speakers = campaign_speeches['speaker'].value_counts().head(5).index

# Filtrar el DataFrame original por esos top speakers y tipo 'Campaign Speech' en septiembre
filter_data_mes = df_speeches[
    (df_speeches['speaker'].isin(top_speakers)) &
    (df_speeches['month_str'] == 'September') &
    (df_speeches['type'] == 'Campaign Speech')
].copy()

# Crear campos que separen la ciudad y el estado en dos nuevas columnas
filter_data_mes[['city', 'state']] = filter_data_mes['location'].str.split(', ', expand=True)
filter_data_mes


total_por_location = filter_data_mes.groupby('state').size().reset_index(name='total_discursos')

total_location=filter_data_mes.groupby('state').size().reset_index(name='total_discursos').sort_values('total_discursos', ascending=False)
total_location





#Visualización por día y mes

#Determinar el top 5 mandatarios con más discursos

top5_mandatarios = df_speeches['speaker'].value_counts().head(5).index.tolist()

# Filtrar sólo top 5
df_top5 = df_speeches[df_speeches['speaker'].isin(top5_mandatarios)].copy()

#  Asegurar que 'date' es datetime
df_top5['date'] = pd.to_datetime(df_top5['date'])

#  Agrupar por día y mandatario: contar discursos
df_grouped = df_top5.groupby(['date', 'speaker']).size().reset_index(name='count')

# Pivotear para cambiar la estructura del dateframe a efetos del gráfico
df_pivot = df_grouped.pivot(index='date', columns='speaker', values='count').fillna(0)

# Ordenar fechas y hacer acumulado (cumsum)
df_pivot = df_pivot.sort_index()
df_pivot.iloc[0] = 0  # primer valor en 0
df_pivot = df_pivot.cumsum().reset_index()

#  Melt para plotear
dfm = pd.melt(df_pivot, id_vars=['date'], value_vars=df_pivot.columns[1:])

# Plotly
fig = px.line(dfm, x="date", y="value", color="speaker")
fig.update_layout(xaxis=dict(tickformat="%d-%m"))

#Actualizar el gráfico
fig.update_layout(
    title='Cantidad de discursos acumulados del Top 5 mandatarios por día del mes (Campaña presidencial 2020 - USA)',
    xaxis_title='Día del mes',
    yaxis_title='Cantidad de discursos'
)
fig.show()










campaign_speeches = df_speeches[df_speeches['type'] == 'Campaign Speech']

# Obtener los top 5 speakers entre esos discursos
top_speakers = campaign_speeches['speaker'].value_counts().head(5).index

# Filtrar el DataFrame original por esos top speakers y tipo 'Campaign Speech'
df_speeches_top_5 = df_speeches[
    (df_speeches['speaker'].isin(top_speakers)) &
    (df_speeches['type'] == 'Campaign Speech')
]
df_speeches_top_5





def clean_text(df, column_name):
    
    result = df[column_name].str.replace(r"^[^\n]*\n", "", regex=True)

    # Eliminar texto entre \n...\n que contenga ":"
    result = result.str.replace(r'\n[^\n]*?:[^\n]*?\n', ' ', regex=True)

    # Eliminar lo que está entre corchetes incluidos los corchetes
    result = result.str.replace(r'\[.*?\]', '', regex=True)

    # Eliminar las horas entre paréntesis (y dejar un espacio)
    result = result.str.replace(r"\([^)]*\)", "", regex=True)

    # Reemplazar saltos de línea por espacio
    result = result.str.replace(r"\n", "", regex=True)

    # Convertir a minúsculas
    result = result.str.lower()

    # Eliminar signos de puntuación
    for punc in ["[", ",", ":", "?", ".", "…", "-", "“", "”", "‘", "]", "%"]:
        result = result.str.replace(re.escape(punc), "", regex=True)

    # Eliminar espacios múltiples
    result = result.str.replace(r'\s+', ' ', regex=True).str.strip()
    
    return result





df_speeches_top_5 = df_speeches_top_5.copy()
df_speeches_top_5["CleanText"] = clean_text(df_speeches_top_5,'text')
df_speeches_top_5





subset = df_speeches_top_5.iloc[1:6]
#  Mostrar CleanText completo de la primera fila del subset
#print(subset.iloc[0]["CleanText"])





df_speeches_top_5["WordList"] = df_speeches_top_5["CleanText"].str.split()





df_speeches_top_5['Word_Count'] = df_speeches_top_5['WordList'].apply(len)
df_speeches_top_5[['speaker','Word_Count']]





# Agrupar por speaker y sumar Word_Count
df_speeches_top5_total_palabras=df_speeches_top_5.groupby('speaker')['Word_Count'].sum().reset_index()

# Renombrar el campo WordCount por Total Words

df_speeches_top5_total_palabras.rename(columns={'Word_Count':'Total_Words'},inplace=True)



df_speeches_top5_total_palabras.sort_values("Total_Words", ascending=False)





# Boxplot múltiple para visualizar cantidad de palabras por candidato

sns.boxplot(data=df_speeches_top_5, x='speaker', y='Word_Count')

plt.title('Cantidad de palabras por candidato')
plt.xlabel('Candidato')
plt.ylabel('Cantidad de palabras')
plt.xticks(rotation=45) 
plt.tight_layout()
plt.show()





fig = px.bar(
    df_speeches_top5_total_palabras.sort_values("Total_Words", ascending=False),
    x="speaker",
    y="Total_Words",
    title="Total de palabras por orador y discurso de campaña (Elecciones USA -2020)",
    labels={"speaker": "Orador", "Total_Words": "Total de Palabras"},
    text="Total_Words"
)

fig.update_traces(textposition="outside")
fig.show()





def tres_palabras_mas_frecuentes(lista_palabras):
    contador = Counter(lista_palabras)
    top3 = contador.most_common(3)
    
    # Rellenar con None si hay menos de 3 palabras
    while len(top3) < 3:
        top3.append((None, 0))
    
    return pd.Series(
        [top3[0][0], top3[0][1], top3[1][0], top3[1][1], top3[2][0], top3[2][1]],
        index=['Word_1', 'Count_1', 'Word_2', 'Count_2', 'Word_3', 'Count_3']
    )

# Agrupar por speaker y sumar las listas de palabras
df_speeches_top_5_agrupado = df_speeches_top_5.groupby('speaker')['WordList'].sum().reset_index()

# Aplicar la función
df_speeches_top_5_agrupado = df_speeches_top_5_agrupado.join(
    df_speeches_top_5_agrupado['WordList'].apply(tres_palabras_mas_frecuentes)
)

# Ordenar si querés ver quién tiene la palabra más repetida más fuerte
df_speeches_top_5_agrupado = df_speeches_top_5_agrupado.sort_values("Count_1", ascending=False)
df_speeches_top_5_agrupado






# Lista de candidatos
candidatos = df_speeches_top_5_agrupado['speaker'].tolist()

# Crear subplots
fig, axs = plt.subplots(1, len(candidatos), figsize=(20, 5))

# Generar una nube por cada candidato
for i, candidato in enumerate(candidatos):
    df_candidato = df_speeches_top_5_agrupado[df_speeches_top_5_agrupado['speaker'] == candidato]

    # Crear diccionario con las 3 palabras y sus conteos
    freqs = {
        df_candidato['Word_1'].values[0]: df_candidato['Count_1'].values[0],
        df_candidato['Word_2'].values[0]: df_candidato['Count_2'].values[0],
        df_candidato['Word_3'].values[0]: df_candidato['Count_3'].values[0],
    }

    wc = WordCloud(width=400, height=400, background_color='white', colormap='Greens').generate_from_frequencies(freqs)
    
    axs[i].imshow(wc, interpolation='bilinear')
    axs[i].axis('off')
    axs[i].set_title(candidato)

plt.tight_layout()
plt.show()










palabras_a_eliminar = [
    'the', 'is', 'and', 'a', 'of', 'to', 'in', 'for', 'on', 'with', 'that', 'by', 'at',
    'you', 'we', 'i', 'this', 'it', 'so', 'are', 'they', 'have', 'he', 'but', 'our', 'be',
    'about', 'going', 'was', 'not', 'it’s', 'as', 'said', 'all', 'what', 'my',
    'me', 'your', 'from', 'an', 'has', 'had', 'them', 'if', 'then', 'there', 'their', 'just',
    'do', 'did', 'can', 'will', 'would', 'should', 'could', 'or', 'because', 'how', 'when', 'which',
    'who', 'whom', 'where', 'why', 'been', 'into', 'than', 'too', 'very', 'some', 'any', 'no', 'yes',
    'more','now','we’re','us','i’m','know','don’t'
]


# Función para limpiar palabras
def limpiar_lista(lista):
    return [p.lower() for p in lista if p.lower() not in palabras_a_eliminar]

# Agrupar por speaker y sumar las listas de palabras
df_speeches_top_5_agrupado = df_speeches_top_5.groupby('speaker')['WordList'].sum().reset_index()

# Limpiar las listas ya agrupadas
df_speeches_top_5_agrupado['WordList'] = df_speeches_top_5_agrupado['WordList'].apply(limpiar_lista)

# Función para obtener las 3 palabras más frecuentes
def tres_palabras_mas_frecuentes(lista_palabras):
    contador = Counter(lista_palabras)
    top3 = contador.most_common(3)
    while len(top3) < 3:
        top3.append((None, 0))
    return pd.Series(
        [top3[0][0], top3[0][1], top3[1][0], top3[1][1], top3[2][0], top3[2][1]],
        index=['Top1_Word', 'Top1_Count', 'Top2_Word', 'Top2_Count', 'Top3_Word', 'Top3_Count']
    )

# Aplicar la función para obtener top 3 palabras
df_speeches_top_5_agrupado = df_speeches_top_5_agrupado.join(
    df_speeches_top_5_agrupado['WordList'].apply(tres_palabras_mas_frecuentes)
)

# Función para palabra más frecuente
def palabra_mas_frecuente(lista_palabras):
    contador = Counter(lista_palabras)
    if contador:
        palabra, cantidad = contador.most_common(1)[0]
    else:
        palabra, cantidad = (None, 0)
    return pd.Series([palabra, cantidad])

# Obtener la palabra más frecuente
df_speeches_top_5_agrupado[['Max_Word', 'Max_Word_Count']] = df_speeches_top_5_agrupado['WordList'].apply(palabra_mas_frecuente)

# Mostrar resultado final
print(df_speeches_top_5_agrupado)



# Obtener los candidatos
candidatos = df_speeches_top_5_agrupado['speaker'].tolist()

# Crear subplots
fig, axs = plt.subplots(1, len(candidatos), figsize=(20, 5))

# Generar una nube por cada candidato
for i, candidato in enumerate(candidatos):
    fila = df_speeches_top_5_agrupado[df_speeches_top_5_agrupado['speaker'] == candidato].iloc[0]
    
    # Diccionario de las tres palabras más frecuentes
    freqs = {
        fila['Top1_Word']: fila['Top1_Count'],
        fila['Top2_Word']: fila['Top2_Count'],
        fila['Top3_Word']: fila['Top3_Count']
    }

    wc = WordCloud(width=400, height=400, background_color='white', colormap='Greens').generate_from_frequencies(freqs)

    axs[i].imshow(wc, interpolation='bilinear')
    axs[i].axis('off')
    axs[i].set_title(candidato)

plt.tight_layout()
plt.show()






# TODO: Construya una matriz de 5x5, donde cada fila y columna corresponden a un candiato/a, 
# y la entrada (i,j) contiene la cantidad de veces que el candiato/a “i” menciona al candiato/a “j”.

speaker_to_lastname = {
    "Donald Trump": "trump",
    "Kamala Harris": "harris",
    "Mike Pence": "pence",
    "Joe Biden": "biden",
    "Bernie Sanders": "sanders"
}

# Filtrar solo los que te interesan
df_filtrado = df_speeches_top_5[df_speeches_top_5['speaker'].isin(speaker_to_lastname.keys())]

# Crear matriz vacía
matriz = pd.DataFrame(0, index=speaker_to_lastname.values(), columns=speaker_to_lastname.values())

# Recorrer cada discurso
for _, row in df_filtrado.iterrows():
    speaker_full = row['speaker']  
    words = row['WordList']          
    speaker_short = speaker_to_lastname[speaker_full]  
    
    # Contar menciones
    for mentioned in speaker_to_lastname.values():
        count = words.count(mentioned)
        matriz.loc[speaker_short, mentioned] += count

# Mostrar
print(matriz)



# mentions_matrix = ...

# Opcional: Genere un grafo dirigido con esa matriz de adyacencia para visualizar las menciones. 
# Puede ser util la biblioteca networkx






# Crear y visualizar el grafo

# Crear un grafo dirigido
G = nx.DiGraph()

# Añadir nodos (candidatos)
G.add_nodes_from(matriz.index)

# Añadir aristas con las menciones de cada candidato
for origen in matriz.index:
    for destino in matriz.columns:
        weight = matriz.loc[origen, destino]
        if weight > 0:
            G.add_edge(origen, destino, weight=weight)

# Posicionamiento de nodos
pos = nx.spring_layout(G, seed=42)

# Dibujar nodos y etiquetas
nx.draw(G, pos, with_labels=True, node_size=1000, node_color="lightcoral", 
        font_size=6, font_weight="bold", alpha=0.4)

# Dibujar etiquetas de las aristas (menciones)
labels = nx.get_edge_attributes(G, 'weight')
nx.draw_networkx_edge_labels(G, pos, edge_labels=labels, font_size=7, label_pos=0.3)

# Dibujar flechas (aristas) más notorias
nx.draw_networkx_edges(G, pos, width=1, arrowsize=5, alpha=0.7)

# Mostrar el grafo
plt.gcf().set_size_inches(8, 6)  # Cambia tamaño de la figura (ancho, alto)
plt.title("Grafo de menciones entre mandatarios en discursos de campaña - USA 2020", fontsize=10)
plt.savefig("grafo_menciones.png", dpi=300, bbox_inches='tight')
plt.show()



